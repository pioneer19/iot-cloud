### Ликбез по docker

Немного сумбурное описание устройства пакетов докера и запуска приложений. Прочитать
нужно целиком, чтобы создалось более-менее стройное впечатление, что такое докер
и как с ним работать. Это обзорное описание, для реальной работы с докером
нужно будет разбираться более детально с нужными командами. Для наших контейнеров
я сделаю отдельное описание ([IoT](./IoT.md)).

Docker - система контейнеризации (минимальной виртуализации), которую используют для запуска
изолированных контейнеров по причине ее минимальных накладных расходов по сравнению
с другими системами изолирования приложений, а также по причине ее удобства для работы.

Докер предоставляет 
* средство изолирования приложений друг от друга (CPU, сеть, файловая система, системные вызовы)
* способ упаковки приложения в пакет
* способ установки пакетов

Приложения в докере выполняются на том же ядре Linux и без какой-либо виртуализации процессора.
По сути докер - это продвинутый chroot или FreeBSD jail. Приложение запакованное в докер
может быть единственным exe'шником, слинкованным статически и оно будет работать, как обычное
приложение, запущенное без докера. Докер лишь создает пространство имен для сети,
ограничивает системны вызовы (root в контейнере не сможет загрузить модуль ядра). Также,
насколько я понимаю, есть возможность задать ограничения по памяти и CPU (cgroup).
Итого, докер позволяет запускать приложения у хостеров, так чтобы разные пользователи
не мешали друг другу и все без какой-либо виртуализации (с ее тормозами и костылями
для обхода этих тормозов).

Идеология работы с докер контейнерами такова - контейнер можно перезапустить в любое время
и он потеряет все свои данные на файловой системе, которые у него были за время предыдущей работы.
После рестарта докер приложение запустится с того образа файловой системы,
который был при создании пакета докера. Отсюда вывод - если приложению нужны
данные, оно их хранит не на файловой системе пакета докера (внешняя база не в докере
или папка на файловой системе хоста).

Файловая система докера устроена слоистым образом. К примеру, кто-то хочет создать
приложение, которому нужна будет Java и Spring. Он берет готовый образ Ubuntu (в виде пакета docker),
например, устанавливает туда Java, spring и свое приложение. В результате будет несколько слоев
на файловой системе пакета докера (Ubuntu, Java, Spring, само приложение). Каждый слой вносит
небольшие тормоза при работе с файловой системой контейнера. Но, такая слоистая структура
может быть полезна, потому что слои можно переиспользовать. Например, кто-то захочет использовать
не Spring на Java, а Red5 на Java, а кому-то Java не нужна, у него RubyOnRails
или Django, но тоже на Ubuntu.
Когда все эти контейнеры будут хоститься на одной машине, там будет для всех контейнеров единственный
экземпляр слоя Ubuntu, Java, Spring, Red5, Ruby, Django и по слою на приложение.

#### Различие пакета и контейнера.
Докер пакет с приложением содержит файловую систему с приложением, и всеми
библиотеками, нужными для работы приложения. Пакет - это способ распространения
и установки приложения (snap построен на нем). Когда приложение запускается,
создается контейнер с еще одним слоем файловой системы, куда и пишутся все изменения.
Файловая система пакета, сколько бы там не было слоев - остается только для чтения.
Поэтому, если остановить контейнер и запустить заново, то слой файловой системы контейнера
создастся заново и данные предыдушего периода работы будут потеряны.
Есть способ остановить контейнер и запусть его заново сохранив его файловую систему.
Но так не делают. Как я уже сказал, файловая система в докере слоистая, каждый слой -
дополнительный тормоз. Кроме того, что делать с обновлением приложения или библиотек...
В общем - перезапуск контейнера в production - это запуск заново с файловой системой
пакета.

#### Создание контейнеров docker
Контейнеры создаются на основе `Dockerfile`. Пример:
```
FROM influxdb:1.8

ENV GF_RENDERER_PLUGIN_CHROME_BIN="/usr/bin/chromium-browser"
RUN apt update; apt upgrade -y
COPY ./influxdb.conf /etc/influxdb/influxdb.conf
USER influxdb
VOLUME /var/lib/influxdb
ENTRYPOINT ["/entrypoint.sh"]
CMD ["influxd"]
```
* `FROM` - указывает, какой пакет использовать в качестве основы, можно взять Ubuntu 
и все установить самому. Есть вариант взять пустой пакет (без единого файла)
и скопировать в него статически слинкованный exe'шник. Тогда на файловой системе пакета
будет единственный файл.
* `COPY` копирует файл с локальной системы внутрь пакета
* `RUN` запускает команды внутри пакета (можно создавать пользователей, например,
  да и вообще запускать любые неинтерактивные скрипты).
* `USER` задает пользователя, от которого будет работать программа внутри запущенного контейнера.
* `ENV` позволяет задать переменные окружения
* `VOLUME` создание тома (файловой системы) для постоянного хранения данных
* `CMD` и `ENTRYPOINT` задают, какую команду/скрипт выполнить по умолчанию при запуске
  контейнера.
  
Кроме файловой системы (файлов приложения и библиотек) в пакете хранится дополнительная
информация, например, команда запуска по умолчанию (контейнер можно просто запустить
и тогда выполнится команда по умолчанию, а можно при запуске явно задать, что запустить
`/bin/bash`, например). Конфигурирование запуска приложения делается через параметры командной
строки (при запуске приложения можно передать команду с аргументами) или через переменные
окружения. Смысл в том, что приложение в контейнере должно как-то узнать, как подключиться
к базе, например, а контейнер создается (обычно) универсальный, да и сама база тоже может
быть в контейнере (большинство таких приложений работает у хостинг-провайдеров), и при 
создании пакета еще не известно, где запустят пакет с базой.

Обновление приложения в контейнере производится пересозданием пакета (ведь все изменения
на файловой системе при перезапуске пакета теряются). 
  
#### Постоянное хранилище данных
Файловая система в докере слоистая и слегка тормозит. К тому же каждый раз контейнер
запускается с образа файловой системы пакета. Для хранения данных используются тома (volume)
или монтируется папка с файловой системы машины (через bind mount). Такое подключение
внешней папки в контейнер работает с производительностью обычной файловой системы.
Также эти данные никто не удаляет при перезапуске контейнера. Какой том (volume)
или папку подмонтировать в контейнер указывается при его запуске в командной строке.
Суть команды `VOLUME` в `Dockerfile` мне до конца не понятна (насколько я понял,
она создает том при создании пакета, но обычно пакеты создают на одном машине, а
production на другой).

По документации разработчиков Docker приоритетным является работа с томами, а не явно
указанными папками. Однако, с явными папками все равно придется работать 
(для бакапа и для начальной загрузки данных). Да и по сути они ничем не отличаются (для нас).
Том (volume) по-моему мнению это такая абстракция для обозначения постоянного
хранилища на файловой системе, потому что для серьезных применений докера
у этого тома могут быть очень разные драйверы для его реализации (nfs, RDBD, Ceph и другие).
Но по сути все эти реализации - это способ обеспечить копирование данных с локальной
папки на другую машину по сети (потому что том - это в любой реализации папка на локальной фаловой системе
или nfs, которая будет локально хранить данные, но не в папке, а в ядре OS). Если хранить
данные не локально, с ними не получится работать быстро, а если не передавать
на другую машину, они потеряются при потере машины и на горячую переключиться не получится
(да и данные можно потерять безвозвратно). Так что том - по сути локальнамя папка.

Работа с томами происходит так. Для начальной заливки данных в том, запускается любой контейнер,
к которому монтируется локальная папка с данными (mount типа bind) и подключается том. Данные
копируются внутри контейнера, контейнер останавливается. Далее запускается (или одновременно,
потому что тома и папки можно подключать к нескольким контейнерам) рабочий контейнер
с подмонтированным томом и работает с данными на нем.